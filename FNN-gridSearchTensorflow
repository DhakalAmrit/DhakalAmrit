{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11715186,"sourceType":"datasetVersion","datasetId":7353654}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Setup\n%matplotlib inline\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Optional: suppress warnings\nimport numpy as np\nfrom numpy import array, hstack\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras import backend as K\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport os\nimport tensorflow as tf\nfrom sklearn.metrics import (mean_absolute_error, mean_squared_error, \n                           max_error, mean_absolute_percentage_error, r2_score)\nfrom sklearn.model_selection import train_test_split\nfrom mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\nimport itertools\nphysical_devices = tf.config.list_physical_devices('GPU')\nif physical_devices:\n    for device in physical_devices:\n        tf.config.experimental.set_memory_growth(device, True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:24:46.932224Z","iopub.execute_input":"2025-05-12T15:24:46.932491Z","iopub.status.idle":"2025-05-12T15:24:46.940591Z","shell.execute_reply.started":"2025-05-12T15:24:46.932469Z","shell.execute_reply":"2025-05-12T15:24:46.939915Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def load_and_prepare_data(file_x_path, file_y_path, n_steps=300):\n    \"\"\"Load and preprocess data for training or testing.\"\"\"\n    X = np.load(file_x_path).T\n    y = np.load(file_y_path).T\n    dataset = hstack((X, y))\n    X, y = split_sequences(dataset, n_steps)\n    n_input = X.shape[1] * X.shape[2]\n    X = X.reshape((X.shape[0], n_input))\n    return X, y, n_input\n\ndef split_sequences(sequences, n_steps):\n    \"\"\"Split sequences into input-output pairs.\"\"\"\n    X, y = list(), list()\n    for i in range(len(sequences)):\n        end_ix = i + n_steps\n        if end_ix > len(sequences):\n            break\n        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n\ndef build_and_train_model(X, y, n_input, n_nodes=100, epochs=5, batch_size=None):\n    \"\"\"Build and train the MLP model, returning model and training history.\"\"\"\n    # Split data into training and validation sets\n    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n    \n    model = Sequential()\n    model.add(Dense(n_nodes, activation='relu', input_dim=n_input))\n    model.add(Dense(1))\n    model.compile(optimizer='adam', loss='mse')\n    \n    print(f\"TRAINING MLP MODEL (nodes={n_nodes}, epochs={epochs}, batch_size={batch_size})...\")\n    history = model.fit(\n        X_train, y_train,\n        validation_data=(X_val, y_val),\n        epochs=epochs,\n        batch_size=batch_size,\n        verbose=1  # Display progress bar per epoch\n    )\n    return model, history.history\n\ndef evaluate_model(model, X_test, y_test):\n    \"\"\"Evaluate the model and return predictions and metrics.\"\"\"\n    print(\"Prediction in progress...\")\n    yhat = model.predict(X_test, verbose=0)\n    metrics, errors = evaluate_regression(y_test, yhat)\n    return yhat, metrics, errors\n\ndef evaluate_regression(y_true, y_pred):\n    \"\"\"Compute regression metrics and errors.\"\"\"\n    y_true = np.ravel(y_true)\n    y_pred = np.ravel(y_pred)\n    errors = y_true - y_pred\n    return {\n        'MAE': mean_absolute_error(y_true, y_pred),\n        'MSE': mean_squared_error(y_true, y_pred),\n        'RMSE': mean_squared_error(y_true, y_pred, squared=False),\n        'R2': r2_score(y_true, y_pred),\n        'Max Error': max_error(y_true, y_pred),\n        'MAPE (%)': mean_absolute_percentage_error(y_true, y_pred) * 100\n    }, errors\n\ndef save_results(temp, y_test, yhat, errors, results_df):\n    \"\"\"Save predictions, errors, and metrics to files.\"\"\"\n    temp_clean = temp.replace('°C', 'C').replace('-', 'n')\n    np.save(f'/kaggle/working/MLP_npy_results/{temp_clean}_true_soc.npy', y_test)\n    np.save(f'/kaggle/working/MLP_npy_results/{temp_clean}_MLP_predicted_soc.npy', yhat)\n    np.save(f'/kaggle/working/MLP_npy_results/{temp_clean}_MLP_errors.npy', errors)\n    results_df.to_csv('/kaggle/working/MLP_prediction_metrics.csv', index=False)\n\ndef plot_soc_and_error(all_predictions):\n    \"\"\"Plot SOC estimation and error for each temperature.\"\"\"\n    fig, axs = plt.subplots(4, 2, figsize=(14, 10),\n                            gridspec_kw={'height_ratios': [3, 1.5, 3, 1.5], 'hspace': 0.3, 'wspace': 0.25})\n    temp_order = ['-10°C', '0°C', '10°C', '25°C']\n    all_predictions_sorted = sorted(all_predictions, key=lambda x: temp_order.index(x[0]))\n\n    for i, (temp, y_true, y_pred, errors) in enumerate(all_predictions_sorted):\n        y_true = np.ravel(y_true) * 100\n        y_pred = np.ravel(y_pred) * 100\n        error = y_pred - y_true\n        seq_length = len(y_true)\n        time_steps = np.arange(seq_length)\n\n        row_soc = (i // 2) * 2\n        col = i % 2\n        row_err = row_soc + 1\n\n        ax_soc = axs[row_soc, col]\n        p1, = ax_soc.plot(time_steps, y_true, 'k-', linewidth=2, label='Observed SOC')\n        p2, = ax_soc.plot(time_steps, y_pred, 'tab:blue', linewidth=1.5, label='Predicted SOC')\n        ax_soc.set_title(f'SOC Estimation @ {temp}', fontsize=14, fontweight='bold')\n        ax_soc.set_ylabel('SOC (%)')\n        ax_soc.grid(True, linestyle='--', alpha=0.5)\n        ax_soc.tick_params(axis='both', labelsize=11)\n        if row_soc == 2:\n            ax_soc.set_xlabel('Time Steps')\n\n        zoom_start = int(0.04 * seq_length)\n        zoom_end = int(0.08 * seq_length)\n        if zoom_end <= zoom_start:\n            zoom_end = min(zoom_start + 50, seq_length)\n        axins = inset_axes(ax_soc, width=\"20%\", height=\"20%\", loc='lower left',\n                           bbox_to_anchor=(0.05, 0.05, 0.9, 0.9),\n                           bbox_transform=ax_soc.transAxes)\n        axins.plot(time_steps, y_true, 'k-', linewidth=2)\n        axins.plot(time_steps, y_pred, 'tab:blue', linewidth=1.5)\n        axins.set_xlim(zoom_start, zoom_end)\n        y_min_zoom = min(np.min(y_true[zoom_start:zoom_end]), np.min(y_pred[zoom_start:zoom_end]))\n        y_max_zoom = max(np.max(y_true[zoom_start:zoom_end]), np.max(y_pred[zoom_start:zoom_end]))\n        axins.set_ylim(y_min_zoom - 1, y_max_zoom + 1)\n        axins.set_xticks([])\n        axins.set_yticks([])\n        mark_inset(ax_soc, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n\n        ax_err = axs[row_err, col]\n        p3, = ax_err.plot(time_steps, error, 'tab:red', linewidth=1.5, label='Error')\n        ax_err.set_ylabel('Error (%)')\n        ax_err.set_xlabel('Time Steps' if row_err == 3 else '')\n        ax_err.grid(True, linestyle='--', alpha=0.5)\n        ax_err.tick_params(axis='both', labelsize=11)\n\n    handles = [p1, p2, p3]\n    labels = ['Observed SOC', 'MLP Predicted SOC', 'Error']\n    fig.legend(handles, labels, loc='lower center', ncol=3, fontsize=14, bbox_to_anchor=(0.5, 0.99))\n    plt.subplots_adjust(left=0.07, right=0.97, top=0.94, bottom=0.06, hspace=0.3, wspace=0.3)\n    fig.savefig('/kaggle/working/MLP_plots/SOC_and_Error_2x2_Grid.pdf', dpi=600)\n    fig.savefig('/kaggle/working/MLP_plots/SOC_and_Error_2x2_Grid.png', dpi=600)\n    plt.show()\n\ndef plot_error_metrics(results_df):\n    \"\"\"Plot error metrics comparison across temperatures.\"\"\"\n    print('Plotting error metrics subplots')\n    plt.figure(figsize=(18, 10))\n    metrics = [\n        ('RMSE', 'red', 'Root Mean Squared Error'),\n        ('MSE', 'orange', 'Mean Squared Error'),\n        ('MAE', 'blue', 'Mean Absolute Error'),\n        ('MAPE (%)', 'purple', 'Mean Absolute Percentage Error'),\n        ('R2', 'green', 'R² Score'),\n        ('Max Error', 'brown', 'Maximum Error')\n    ]\n\n    for i, (metric, color, title) in enumerate(metrics, 1):\n        plt.subplot(2, 3, i)\n        if metric == 'R2':\n            bars = plt.bar(results_df['Temperature'], results_df[metric], color=color)\n            plt.axhline(y=1.0, color='gray', linestyle='--', linewidth=0.8)\n        else:\n            bars = plt.bar(results_df['Temperature'], results_df[metric], color=color)\n        \n        for bar in bars:\n            height = bar.get_height()\n            plt.text(bar.get_x() + bar.get_width()/2., height,\n                     f'{height:.4f}',\n                     ha='center', va='bottom', fontsize=9)\n        \n        plt.title(f'MLP {title} Comparison')\n        plt.ylabel(metric)\n        plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n        plt.xticks(rotation=45)\n\n    plt.tight_layout()\n    plt.savefig('/kaggle/working/MLP_plots/MLP_all_error_metrics_comparison.png', \n                dpi=600, bbox_inches='tight')\n    plt.show()\n    print(\"Plotting DONE!\")\n\ndef plot_training_evolution(histories, configs, title_prefix=\"Training_Evolution\"):\n    \"\"\"Plot training and validation loss over epochs for each batch size.\"\"\"\n    batch_sizes = sorted(set(config['n_batch'] for config in configs))\n    \n    for batch_size in batch_sizes:\n        plt.figure(figsize=(10, 6))\n        for config, history in histories:\n            if config['n_batch'] != batch_size:\n                continue\n            label = (f\"n_steps={config['n_steps']}, n_nodes={config['n_nodes']}, \"\n                     f\"n_epochs={config['n_epochs']}\")\n            plt.plot(history['loss'], label=f\"{label} (Train)\", linestyle='-')\n            plt.plot(history['val_loss'], label=f\"{label} (Val)\", linestyle='--')\n        \n        plt.title(f\"Training Evolution (Batch Size = {batch_size})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"MSE Loss\")\n        plt.grid(True, linestyle='--', alpha=0.7)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n        plt.tight_layout()\n        plt.savefig(f'/kaggle/working/MLP_plots/{title_prefix}_batch_size_{batch_size}.png', \n                    dpi=600, bbox_inches='tight')\n        plt.show()\n\ndef model_configs():\n    \"\"\"Generate a list of model configurations to try.\"\"\"\n    n_input = [300, 500, 700]\n    n_nodes = [55, 128, 256]\n    n_epochs = [5, 50, 120]\n    n_batch = [128, 256, 512, 1024]\n    configs = []\n    for inp, nodes, epochs, batch in itertools.product(n_input, n_nodes, n_epochs, n_batch):\n        configs.append({\n            'n_steps': inp,\n            'n_nodes': nodes,\n            'n_epochs': epochs,\n            'n_batch': batch\n        })\n    return configs\n\ndef repeat_evaluate(X_train, y_train, X_test, y_test, config, n_repeats=3):\n    \"\"\"Repeat model training and evaluation n times and average metrics.\"\"\"\n    all_metrics = []\n    histories = []\n    for i in range(n_repeats):\n        print(f\"Repeat {i+1}/{n_repeats} for config: {config}\")\n        X_train_config, y_train_config, n_input = load_and_prepare_data(\n            '/kaggle/input/lg-hg2-npy-data/train/TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs_X.npy',\n            '/kaggle/input/lg-hg2-npy-data/train/TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs_Y.npy',\n            n_steps=config['n_steps']\n        )\n        X_test_config, y_test_config, _ = load_and_prepare_data(\n            X_test_file, y_test_file, n_steps=config['n_steps']\n        )\n        model, history = build_and_train_model(\n            X_train_config, y_train_config, n_input,\n            n_nodes=config['n_nodes'], epochs=config['n_epochs'], batch_size=config['n_batch']\n        )\n        _, metrics, _ = evaluate_model(model, X_test_config, y_test_config)\n        all_metrics.append(metrics)\n        histories.append(history)\n        K.clear_session()  # Clear session to prevent CUDA errors\n    avg_metrics = {}\n    for key in all_metrics[0].keys():\n        avg_metrics[key] = np.mean([m[key] for m in all_metrics])\n    return avg_metrics, histories\n\ndef grid_search(configs, train_x_path, train_y_path, test_files, n_repeats=3, sort_metric='RMSE'):\n    \"\"\"Evaluate all configurations and sort by specified metric.\"\"\"\n    grid_results = []\n    all_histories = []\n    \n    for config in configs:\n        print(f\"Evaluating config: {config}\")\n        config_results = {'config': config}\n        for temp, x_path, y_path in test_files:\n            global X_test_file, y_test_file\n            X_test_file, y_test_file = x_path, y_path\n            metrics, histories = repeat_evaluate(\n                train_x_path, train_y_path, x_path, y_path, config, n_repeats=n_repeats\n            )\n            metrics['Temperature'] = temp\n            config_results[temp] = metrics\n            all_histories.extend([(config, h) for h in histories])\n        \n        grid_results.append(config_results)\n    \n    rows = []\n    for result in grid_results:\n        for temp, metrics in [(k, v) for k, v in result.items() if k != 'config']:\n            row = {'n_steps': result['config']['n_steps'],\n                   'n_nodes': result['config']['n_nodes'],\n                   'n_epochs': result['config']['n_epochs'],\n                   'n_batch': result['config']['n_batch'],\n                   'Temperature': metrics['Temperature']}\n            row.update(metrics)\n            rows.append(row)\n    \n    results_df = pd.DataFrame(rows)\n    sorted_df = results_df.sort_values(by=[sort_metric, 'Temperature'])\n    sorted_df.to_csv('/kaggle/working/MLP_grid_search_results.csv', index=False)\n    \n    # Plot training evolution for all configurations\n    plot_training_evolution(all_histories, configs, title_prefix=\"Grid_Search_Training_Evolution\")\n    \n    return sorted_df\n\ndef main():\n    \"\"\"Main function to orchestrate the workflow.\"\"\"\n    os.makedirs('/kaggle/working/MLP_npy_results', exist_ok=True)\n    os.makedirs('/kaggle/working/MLP_plots', exist_ok=True)\n\n    train_x_path = '/kaggle/input/lg-hg2-npy-data/train/TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs_X.npy'\n    train_y_path = '/kaggle/input/lg-hg2-npy-data/train/TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs_Y.npy'\n\n    test_files = [\n        ('-10°C', '/kaggle/input/lg-hg2-npy-data/test/01_TEST_LGHG2@n10degC_Norm_(05_Inputs)_X.npy',\n                  '/kaggle/input/lg-hg2-npy-data/test/01_TEST_LGHG2@n10degC_Norm_(05_Inputs)_Y.npy'),\n        ('0°C', '/kaggle/input/lg-hg2-npy-data/test/02_TEST_LGHG2@0degC_Norm_(05_Inputs)_X.npy',\n                '/kaggle/input/lg-hg2-npy-data/test/02_TEST_LGHG2@0degC_Norm_(05_Inputs)_Y.npy'),\n        ('10°C', '/kaggle/input/lg-hg2-npy-data/test/03_TEST_LGHG2@10degC_Norm_(05_Inputs)_X.npy',\n                 '/kaggle/input/lg-hg2-npy-data/test/03_TEST_LGHG2@10degC_Norm_(05_Inputs)_Y.npy'),\n        ('25°C', '/kaggle/input/lg-hg2-npy-data/test/04_TEST_LGHG2@25degC_Norm_(05_Inputs)_X.npy',\n                 '/kaggle/input/lg-hg2-npy-data/test/04_TEST_LGHG2@25degC_Norm_(05_Inputs)_Y.npy')\n    ]\n\n    print(\"Starting grid search...\")\n    configs = model_configs()\n    grid_results_df = grid_search(configs, train_x_path, train_y_path, test_files, n_repeats=3, sort_metric='RMSE')\n    \n    print(\"\\nGrid Search Results (sorted by RMSE):\")\n    print(grid_results_df)\n\n    best_config = grid_results_df.groupby(['n_steps', 'n_nodes', 'n_epochs', 'n_batch'])['RMSE'].mean().idxmin()\n    best_config_dict = {\n        'n_steps': best_config[0],\n        'n_nodes': best_config[1],\n        'n_epochs': best_config[2],\n        'n_batch': best_config[3]\n    }\n    print(f\"\\nBest configuration: {best_config_dict}\")\n\n    print(\"\\nEvaluating best configuration...\")\n    X_train, y_train, n_input = load_and_prepare_data(train_x_path, train_y_path, n_steps=best_config_dict['n_steps'])\n    model, best_history = build_and_train_model(\n        X_train, y_train, n_input,\n        n_nodes=best_config_dict['n_nodes'],\n        epochs=best_config_dict['n_epochs'],\n        batch_size=best_config_dict['n_batch']\n    )\n\n    results = []\n    all_predictions = []\n\n    for temp, x_path, y_path in test_files:\n        X_test, y_test, _ = load_and_prepare_data(x_path, y_path, n_steps=best_config_dict['n_steps'])\n        yhat, metrics, errors = evaluate_model(model, X_test, y_test)\n        metrics['Temperature'] = temp\n        results.append(metrics)\n        all_predictions.append((temp, y_test, yhat, errors))\n        save_results(temp, y_test, yhat, errors, pd.DataFrame(results))\n\n    results_df = pd.DataFrame(results)\n    print(\"\\nPerformance Metrics Across Temperatures (Best Config):\")\n    print(results_df.set_index('Temperature'))\n\n    # Plot training evolution for best configuration\n    plot_training_evolution(\n        [(best_config_dict, best_history)],\n        [best_config_dict],\n        title_prefix=f\"Best_Config_Training_Evolution_n_steps_{best_config_dict['n_steps']}_\"\n                    f\"nodes_{best_config_dict['n_nodes']}_epochs_{best_config_dict['n_epochs']}_\"\n                    f\"batch_{best_config_dict['n_batch']}\"\n    )\n\n    plot_soc_and_error(all_predictions)\n    plot_error_metrics(results_df)\n    K.clear_session()  # Clear session after final evaluation\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:24:50.547279Z","iopub.execute_input":"2025-05-12T15:24:50.547550Z","iopub.status.idle":"2025-05-12T15:24:50.583373Z","shell.execute_reply.started":"2025-05-12T15:24:50.547529Z","shell.execute_reply":"2025-05-12T15:24:50.582632Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"%%time\nmain()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T14:23:21.497338Z","iopub.execute_input":"2025-05-12T14:23:21.497874Z","iopub.status.idle":"2025-05-12T15:24:28.680987Z","shell.execute_reply.started":"2025-05-12T14:23:21.497848Z","shell.execute_reply":"2025-05-12T15:24:28.680050Z"}},"outputs":[{"name":"stdout","text":"Starting grid search...\nEvaluating config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 1}\nRepeat 1/3 for config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 1}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\nI0000 00:00:1747059806.121853      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"TRAINING MLP MODEL (nodes=55, epochs=5, batch_size=1)...\nEpoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1747059816.001390      93 service.cc:148] XLA service 0x7aca80006220 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1747059816.001828      93 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1747059816.142545      93 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m   139/535725\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:45\u001b[0m 1ms/step - loss: 0.4416 ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1747059816.408507      93 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m535725/535725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 1ms/step - loss: 0.0036 - val_loss: 0.0018\nEpoch 2/5\n\u001b[1m535725/535725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0025\nEpoch 3/5\n\u001b[1m535725/535725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m689s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0023\nEpoch 4/5\n\u001b[1m535725/535725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m695s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0016\nEpoch 5/5\n\u001b[1m535725/535725\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m691s\u001b[0m 1ms/step - loss: 0.0025 - val_loss: 0.0021\nPrediction in progress...\nRepeat 2/3 for config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 1}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"TRAINING MLP MODEL (nodes=55, epochs=5, batch_size=1)...\nEpoch 1/5\n\u001b[1m173529/535725\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:23\u001b[0m 1ms/step - loss: 0.0077","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2394561018.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting grid search...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mconfigs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0mgrid_results_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RMSE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nGrid Search Results (sorted by RMSE):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2394561018.py\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(configs, train_x_path, train_y_path, test_files, n_repeats, sort_metric)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mglobal\u001b[0m \u001b[0mX_test_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mX_test_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             metrics, histories = repeat_evaluate(\n\u001b[0m\u001b[1;32m    249\u001b[0m                 \u001b[0mtrain_x_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             )\n","\u001b[0;32m/tmp/ipykernel_31/2394561018.py\u001b[0m in \u001b[0;36mrepeat_evaluate\u001b[0;34m(X_train, y_train, X_test, y_test, config, n_repeats)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mX_test_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_steps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         )\n\u001b[0;32m--> 224\u001b[0;31m         model, history = build_and_train_model(\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0mX_train_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mn_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_nodes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_batch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/2394561018.py\u001b[0m in \u001b[0;36mbuild_and_train_model\u001b[0;34m(X, y, n_input, n_nodes, epochs, batch_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"TRAINING MLP MODEL (nodes={n_nodes}, epochs={epochs}, batch_size={batch_size})...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# registered for PartitionedCall, so recording this operation confuses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;31m# forwardprop code (GradientTape manages to ignore it).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m             outputs = self._bound_context.call_function(\n","\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":3}]}