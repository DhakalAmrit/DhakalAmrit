{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11715186,"sourceType":"datasetVersion","datasetId":7353654}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Cell 1: Setup\n%matplotlib inline\nimport os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # Optional: suppress warnings\nimport numpy as np\nfrom numpy import array, hstack\nimport itertools # for grid search\nimport gc\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1.inset_locator import inset_axes, mark_inset\n\n# deep learning-\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, InputLayer\nfrom keras.models import Model\nfrom keras.layers import Input, Dense\nimport tensorflow.keras.backend as K\n\n# metrics\nfrom sklearn.metrics import (mean_absolute_error, mean_squared_error, \n                           max_error, mean_absolute_percentage_error, r2_score)\nfrom sklearn.model_selection import train_test_split\n\n\nphysical_devices = tf.config.list_physical_devices('GPU')\nif physical_devices:\n    for device in physical_devices:\n        tf.config.experimental.set_memory_growth(device, True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T03:58:00.922018Z","iopub.execute_input":"2025-05-13T03:58:00.922645Z","iopub.status.idle":"2025-05-13T03:58:00.929987Z","shell.execute_reply.started":"2025-05-13T03:58:00.922605Z","shell.execute_reply":"2025-05-13T03:58:00.929228Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"def load_and_prepare_data(file_x_path, file_y_path, n_steps=300):\n    \"\"\"Load and preprocess data for training or testing.\"\"\"\n    try:\n        X = np.load(file_x_path, allow_pickle=True).T\n        y = np.load(file_y_path, allow_pickle=True).T\n        if np.any(np.isnan(X)) or np.any(np.isnan(y)):\n            raise ValueError(\"NaN values detected in input data\")\n        dataset = np.hstack((X, y))\n        X, y = split_sequences(dataset, n_steps)\n        n_input = X.shape[1] * X.shape[2]\n        X = X.reshape((X.shape[0], n_input))\n        print(f\"Loaded data: X.shape={X.shape}, y.shape={y.shape}, n_input={n_input}\")\n        return X, y, n_input\n    except Exception as e:\n        print(f\"Error in load_and_prepare_data: {e}\")\n        raise\n\ndef split_sequences(sequences, n_steps):\n    \"\"\"Split sequences into input-output pairs.\"\"\"\n    X, y = list(), list()\n    for i in range(len(sequences)):\n        end_ix = i + n_steps\n        if end_ix > len(sequences):\n            break\n        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n        X.append(seq_x)\n        y.append(seq_y)\n    return array(X), array(y)\n\ndef build_and_train_model(X, y, n_input, n_nodes=100, epochs=5, batch_size=None):\n    \"\"\"Build and train the MLP model, returning model and training history.\"\"\"\n    # Split data into training and validation sets\n    # Assume X and y are numpy arrays or pandas DataFrame/Series\n    n_samples = len(X)\n    split_index = int(n_samples * 0.9)  # 90% for training\n    n_features = X.shape[1]\n    # Sequential split for time series\n    X_train, X_val = X[:split_index], X[split_index:]\n    y_train, y_val = y[:split_index], y[split_index:]\n\n    #model = Sequential()\n    #model.add(Dense(n_nodes, activation='relu',input_dim=n_input))\n    #model.add(Dense(1))\n    #model.compile(optimizer='adam', loss='mse')\n    \n    inputs = Input(shape=(n_input,))\n    x = Dense(n_nodes, activation='relu')(inputs)        # First hidden layer\n    x = Dense(n_nodes, activation='relu')(x)             # Second hidden layer\n    x = Dense(n_nodes // 2, activation='relu')(x)        # Third hidden layer with fewer nodes (optional)\n    outputs = Dense(1)(x)                                # Output layer\n    \n    model = Model(inputs=inputs, outputs=outputs)\n    model.compile(optimizer='adam', loss='mse')\n\n    print(\"-----------------------------------------------------------------------------------------------\")\n    print(f\"******TRAINING MLP MODEL WITH, nodes={n_nodes}, epochs={epochs}, batch_size={batch_size}-******\")\n    print(\"-----------------------------------------------------------------------------------------------\")\n    model.summary()\n    \n    history = model.fit(\n        X_train, y_train,\n        validation_data=(X_val, y_val),\n        epochs=epochs,\n        batch_size=batch_size,\n        verbose=1  # Display progress bar per epoch\n    )\n    return model, history.history\ndef build_and_train_model(dataset, n_input, n_nodes=100, epochs=5, batch_size=256):\n    \"\"\"Build and train the MLP model using tf.data.Dataset.\"\"\"\n    try:\n        dataset_size = tf.data.experimental.cardinality(dataset).numpy()\n        train_size = int(0.8 * dataset_size)\n        train_dataset = dataset.take(train_size).shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n        val_dataset = dataset.skip(train_size).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n        model = Sequential([\n            Dense(n_nodes, activation='relu', input_dim=n_input),\n            Dense(n_nodes, activation='relu'),\n            Dense(n_nodes // 2, activation='relu'),\n            Dense(1, dtype='float32')  # Mixed precision requires float32 output\n        ])\n        model.compile(optimizer='adam', loss='mse')\n        print(f\"TRAINING MLP MODEL (nodes={n_nodes}, epochs={epochs}, batch_size={batch_size})...\")\n        history = model.fit(\n            train_dataset,\n            validation_data=val_dataset,\n            epochs=epochs,\n            verbose=1\n        )\n        return model, history.history\n    except Exception as e:\n        print(f\"Error in build_and_train_model: {e}\")\n        raise\n        \n\n\ndef evaluate_model(model, dataset):\n    \"\"\"Evaluate the model on a tf.data.Dataset and return predictions and metrics.\"\"\"\n    try:\n        print(\"Prediction in progress...\")\n        X_test, y_test = [], []\n        for x, y in dataset.unbatch():\n            X_test.append(x.numpy())\n            y_test.append(y.numpy())\n        X_test, y_test = np.array(X_test), np.array(y_test)\n        yhat = model.predict(X_test, verbose=1)\n        metrics, errors = evaluate_regression(y_test, yhat)\n        return yhat, metrics, errors\n    except Exception as e:\n        print(f\"Error in evaluate_model: {e}\")\n        raise\n\ndef evaluate_regression(y_true, y_pred):\n    \"\"\"Compute regression metrics and errors.\"\"\"\n    y_true = np.ravel(y_true)\n    y_pred = np.ravel(y_pred)\n    errors = y_true - y_pred\n    return {\n        'MAE': mean_absolute_error(y_true, y_pred),\n        'MSE': mean_squared_error(y_true, y_pred),\n        'RMSE': mean_squared_error(y_true, y_pred, squared=False),\n        'R2': r2_score(y_true, y_pred),\n        'Max Error': max_error(y_true, y_pred),\n        'MAPE (%)': mean_absolute_percentage_error(y_true, y_pred) * 100\n    }, errors\n\ndef save_results(temp, y_test, yhat, errors, results_df):\n    \"\"\"Save predictions, errors, and metrics to files.\"\"\"\n    temp_clean = temp.replace('°C', 'C').replace('-', 'n')\n    np.save(f'/kaggle/working/MLP_npy_results/{temp_clean}_true_soc.npy', y_test)\n    np.save(f'/kaggle/working/MLP_npy_results/{temp_clean}_MLP_predicted_soc.npy', yhat)\n    np.save(f'/kaggle/working/MLP_npy_results/{temp_clean}_MLP_errors.npy', errors)\n    results_df.to_csv('/kaggle/working/MLP_prediction_metrics.csv', index=False)\n\ndef plot_soc_and_error(all_predictions):\n    \"\"\"Plot SOC estimation and error for each temperature.\"\"\"\n    fig, axs = plt.subplots(4, 2, figsize=(14, 10),\n                            gridspec_kw={'height_ratios': [3, 1.5, 3, 1.5], 'hspace': 0.3, 'wspace': 0.25})\n    temp_order = ['-10°C', '0°C', '10°C', '25°C']\n    all_predictions_sorted = sorted(all_predictions, key=lambda x: temp_order.index(x[0]))\n\n    for i, (temp, y_true, y_pred, errors) in enumerate(all_predictions_sorted):\n        y_true = np.ravel(y_true) * 100\n        y_pred = np.ravel(y_pred) * 100\n        error = y_pred - y_true\n        seq_length = len(y_true)\n        time_steps = np.arange(seq_length)\n\n        row_soc = (i // 2) * 2\n        col = i % 2\n        row_err = row_soc + 1\n\n        ax_soc = axs[row_soc, col]\n        p1, = ax_soc.plot(time_steps, y_true, 'k-', linewidth=2, label='Observed SOC')\n        p2, = ax_soc.plot(time_steps, y_pred, 'tab:blue', linewidth=1.5, label='Predicted SOC')\n        ax_soc.set_title(f'SOC Estimation @ {temp}', fontsize=14, fontweight='bold')\n        ax_soc.set_ylabel('SOC (%)')\n        ax_soc.grid(True, linestyle='--', alpha=0.5)\n        ax_soc.tick_params(axis='both', labelsize=11)\n        if row_soc == 2:\n            ax_soc.set_xlabel('Time Steps')\n\n        zoom_start = int(0.04 * seq_length)\n        zoom_end = int(0.08 * seq_length)\n        if zoom_end <= zoom_start:\n            zoom_end = min(zoom_start + 50, seq_length)\n        axins = inset_axes(ax_soc, width=\"20%\", height=\"20%\", loc='lower left',\n                           bbox_to_anchor=(0.05, 0.05, 0.9, 0.9),\n                           bbox_transform=ax_soc.transAxes)\n        axins.plot(time_steps, y_true, 'k-', linewidth=2)\n        axins.plot(time_steps, y_pred, 'tab:blue', linewidth=1.5)\n        axins.set_xlim(zoom_start, zoom_end)\n        y_min_zoom = min(np.min(y_true[zoom_start:zoom_end]), np.min(y_pred[zoom_start:zoom_end]))\n        y_max_zoom = max(np.max(y_true[zoom_start:zoom_end]), np.max(y_pred[zoom_start:zoom_end]))\n        axins.set_ylim(y_min_zoom - 1, y_max_zoom + 1)\n        axins.set_xticks([])\n        axins.set_yticks([])\n        mark_inset(ax_soc, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n\n        ax_err = axs[row_err, col]\n        p3, = ax_err.plot(time_steps, error, 'tab:red', linewidth=1.5, label='Error')\n        ax_err.set_ylabel('Error (%)')\n        ax_err.set_xlabel('Time Steps' if row_err == 3 else '')\n        ax_err.grid(True, linestyle='--', alpha=0.5)\n        ax_err.tick_params(axis='both', labelsize=11)\n\n    handles = [p1, p2, p3]\n    labels = ['Observed SOC', 'MLP Predicted SOC', 'Error']\n    fig.legend(handles, labels, loc='lower center', ncol=3, fontsize=14, bbox_to_anchor=(0.5, 0.99))\n    plt.subplots_adjust(left=0.07, right=0.97, top=0.94, bottom=0.06, hspace=0.3, wspace=0.3)\n    fig.savefig('/kaggle/working/MLP_plots/SOC_and_Error_2x2_Grid.pdf', dpi=600)\n    fig.savefig('/kaggle/working/MLP_plots/SOC_and_Error_2x2_Grid.png', dpi=600)\n    plt.show()\n\ndef plot_error_metrics(results_df):\n    \"\"\"Plot error metrics comparison across temperatures.\"\"\"\n    print('Plotting error metrics subplots')\n    plt.figure(figsize=(18, 10))\n    metrics = [\n        ('RMSE', 'red', 'Root Mean Squared Error'),\n        ('MSE', 'orange', 'Mean Squared Error'),\n        ('MAE', 'blue', 'Mean Absolute Error'),\n        ('MAPE (%)', 'purple', 'Mean Absolute Percentage Error'),\n        ('R2', 'green', 'R² Score'),\n        ('Max Error', 'brown', 'Maximum Error')\n    ]\n\n    for i, (metric, color, title) in enumerate(metrics, 1):\n        plt.subplot(2, 3, i)\n        if metric == 'R2':\n            bars = plt.bar(results_df['Temperature'], results_df[metric], color=color)\n            plt.axhline(y=1.0, color='gray', linestyle='--', linewidth=0.8)\n        else:\n            bars = plt.bar(results_df['Temperature'], results_df[metric], color=color)\n        \n        for bar in bars:\n            height = bar.get_height()\n            plt.text(bar.get_x() + bar.get_width()/2., height,\n                     f'{height:.4f}',\n                     ha='center', va='bottom', fontsize=9)\n        \n        plt.title(f'MLP {title} Comparison')\n        plt.ylabel(metric)\n        plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n        plt.xticks(rotation=45)\n\n    plt.tight_layout()\n    plt.savefig('/kaggle/working/MLP_plots/MLP_all_error_metrics_comparison.png', \n                dpi=600, bbox_inches='tight')\n    plt.show()\n    print(\"Plotting DONE!\")\n\ndef plot_training_evolution(histories, configs, title_prefix=\"Training_Evolution\"):\n    \"\"\"Plot training and validation loss over epochs for each batch size.\"\"\"\n    batch_sizes = sorted(set(config['n_batch'] for config in configs))\n    \n    for batch_size in batch_sizes:\n        plt.figure(figsize=(10, 6))\n        for config, history in histories:\n            if config['n_batch'] != batch_size:\n                continue\n            label = (f\"n_steps={config['n_steps']}, n_nodes={config['n_nodes']}, \"\n                     f\"n_epochs={config['n_epochs']}\")\n            plt.plot(history['loss'], label=f\"{label} (Train)\", linestyle='-')\n            plt.plot(history['val_loss'], label=f\"{label} (Val)\", linestyle='--')\n        \n        plt.title(f\"Training Evolution (Batch Size = {batch_size})\")\n        plt.xlabel(\"Epoch\")\n        plt.ylabel(\"MSE Loss\")\n        plt.grid(True, linestyle='--', alpha=0.7)\n        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n        plt.tight_layout()\n        plt.savefig(f'/kaggle/working/MLP_plots/{title_prefix}_batch_size_{batch_size}.png', \n                    dpi=600, bbox_inches='tight')\n        plt.show()\n\n\ndef model_configs():\n    \"\"\"Generate a list of model configurations to try.\"\"\"\n    n_steps = [300, 500, 700]\n    n_nodes = [55, 128, 256]\n    n_epochs = [5, 50, 120]\n    n_batch = [32, 150, 256]\n    configs = []\n    for inp, nodes, epochs, batch in itertools.product(n_steps, n_nodes, n_epochs, n_batch):\n        configs.append({\n            'n_steps': inp,\n            'n_nodes': nodes,\n            'n_epochs': epochs,\n            'n_batch': batch\n        })\n    print(f\"Generated {len(configs)} configurations: {configs[:5]}...\")  # Show first 5 for brevity\n    return configs\n\ndef repeat_evaluate(train_x_path, train_y_path, test_files, config, n_repeats=1):\n    \"\"\"Train model once and evaluate on all test temperatures.\"\"\"\n    all_metrics = []\n    histories = []\n    for i in range(n_repeats):\n        print(f\"Repeat {i+1}/{n_repeats} for config: {config}\")\n        try:\n            # Train model once\n            train_dataset, n_input = load_and_prepare_data(\n                train_x_path, train_y_path, n_steps=config['n_steps'], batch_size=config['n_batch']\n            )\n            model, history = build_and_train_model(\n                train_dataset, n_input,\n                n_nodes=config['n_nodes'], epochs=config['n_epochs'], batch_size=config['n_batch']\n            )\n            histories.append(history)\n            \n            # Evaluate on all test temperatures\n            temp_metrics = {}\n            for temp, x_path, y_path in test_files:\n                print(f\"Testing at temperature {temp} with config: {config}\")\n                test_dataset, _ = load_and_prepare_data(\n                    x_path, y_path, n_steps=config['n_steps'], batch_size=config['n_batch']\n                )\n                yhat, metrics, errors = evaluate_model(model, test_dataset)\n                metrics['Temperature'] = temp\n                temp_metrics[temp] = (metrics, yhat, errors)\n            all_metrics.append(temp_metrics)\n        except Exception as e:\n            print(f\"Error in repeat_evaluate (repeat {i+1}): {e}\")\n            continue\n        finally:\n            K.clear_session()\n            if 'model' in locals():\n                del model\n            gc.collect()\n            tf.keras.backend.clear_session()\n    if not all_metrics:\n        raise ValueError(\"No successful evaluations completed\")\n    return all_metrics, histories\n\ndef grid_search(configs, train_x_path, train_y_path, test_files, n_repeats=1, sort_metric='RMSE'):\n    \"\"\"Evaluate all configurations and sort by specified metric.\"\"\"\n    grid_results = []\n    all_histories = []\n    \n    for idx, config in enumerate(configs):\n        print(f\"Evaluating config {idx+1}/{len(configs)}: {config}\")\n        config_results = {'config': config}\n        try:\n            for temp, x_path, y_path in test_files:\n                print(f\"Testing at temperature {temp} with config: {config}\")\n                metrics, histories = repeat_evaluate(\n                    train_x_path, train_y_path, x_path, y_path, config, n_repeats=n_repeats\n                )\n                metrics['Temperature'] = temp\n                config_results[temp] = metrics\n                all_histories.extend([(config, h) for h in histories])\n            grid_results.append(config_results)\n        except Exception as e:\n            print(f\"Error evaluating config {config}: {e}\")\n            continue\n    \n    rows = []\n    for result in grid_results:\n        for temp, metrics in [(k, v) for k, v in result.items() if k != 'config']:\n            row = {\n                'n_steps': result['config']['n_steps'],\n                'n_nodes': result['config']['n_nodes'],\n                'n_epochs': result['config']['n_epochs'],\n                'n_batch': result['config']['n_batch'],\n                'Temperature': metrics['Temperature']\n            }\n            row.update(metrics)\n            rows.append(row)\n    \n    results_df = pd.DataFrame(rows)\n    if results_df.empty:\n        print(\"No results collected. Check for errors in evaluation.\")\n        return results_df\n    sorted_df = results_df.sort_values(by=[sort_metric, 'Temperature'])\n    sorted_df.to_csv('/kaggle/working/MLP_grid_search_results.csv', index=False)\n    \n    try:\n        plot_training_evolution(all_histories, configs, title_prefix=\"Grid_Search_Training_Evolution\")\n    except Exception as e:\n        print(f\"Error in plot_training_evolution: {e}\")\n    \n    return sorted_df\n    \n\ndef main():\n    os.makedirs('/kaggle/working/MLP_npy_results', exist_ok=True)\n    os.makedirs('/kaggle/working/MLP_plots', exist_ok=True)\n\n    # Configure GPU\n    gpus = tf.config.list_physical_devices('GPU')\n    if gpus:\n        try:\n            tf.config.experimental.set_memory_growth(gpus[0], True)\n            print(\"GPU memory growth enabled\")\n        except Exception as e:\n            print(f\"Error configuring GPU: {e}\")\n\n    train_x_path = '/kaggle/input/lg-hg2-npy-data/train/TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs_X.npy'\n    train_y_path = '/kaggle/input/lg-hg2-npy-data/train/TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs_Y.npy'\n\n    test_files = [\n        ('-10°C', '/kaggle/input/lg-hg2-npy-data/test/01_TEST_LGHG2@n10degC_Norm_(05_Inputs)_X.npy',\n                  '/kaggle/input/lg-hg2-npy-data/test/01_TEST_LGHG2@n10degC_Norm_(05_Inputs)_Y.npy'),\n        ('0°C', '/kaggle/input/lg-hg2-npy-data/test/02_TEST_LGHG2@0degC_Norm_(05_Inputs)_X.npy',\n                '/kaggle/input/lg-hg2-npy-data/test/02_TEST_LGHG2@0degC_Norm_(05_Inputs)_Y.npy'),\n        ('10°C', '/kaggle/input/lg-hg2-npy-data/test/03_TEST_LGHG2@10degC_Norm_(05_Inputs)_X.npy',\n                 '/kaggle/input/lg-hg2-npy-data/test/03_TEST_LGHG2@10degC_Norm_(05_Inputs)_Y.npy'),\n        ('25°C', '/kaggle/input/lg-hg2-npy-data/test/04_TEST_LGHG2@25degC_Norm_(05_Inputs)_X.npy',\n                 '/kaggle/input/lg-hg2-npy-data/test/04_TEST_LGHG2@25degC_Norm_(05_Inputs)_Y.npy')\n    ]\n\n    print(\"Starting grid search...\")\n    configs = model_configs()[:3]  # Debug with first 3 configs\n    grid_results_df = grid_search(configs, train_x_path, train_y_path, test_files, n_repeats=1, sort_metric='RMSE')\n    \n    print(\"\\nGrid Search Results (sorted by RMSE):\")\n    print(grid_results_df)\n\n    if grid_results_df.empty:\n        print(\"Grid search failed to produce results.\")\n        return\n\n    best_config = grid_results_df.groupby(['n_steps', 'n_nodes', 'n_epochs', 'n_batch'])['RMSE'].mean().idxmin()\n    best_config_dict = {\n        'n_steps': best_config[0],\n        'n_nodes': best_config[1],\n        'n_epochs': best_config[2],\n        'n_batch': best_config[3]\n    }\n    print(f\"\\nBest configuration: {best_config_dict}\")\n\n    print(\"\\nEvaluating best configuration...\")\n    try:\n        X_train, y_train, n_input = load_and_prepare_data(train_x_path, train_y_path, n_steps=best_config_dict['n_steps'])\n        model, best_history = build_and_train_model(\n            X_train, y_train, n_input,\n            n_nodes=best_config_dict['n_nodes'],\n            epochs=best_config_dict['n_epochs'],\n            batch_size=best_config_dict['n_batch']\n        )\n\n        results = []\n        all_predictions = []\n\n        for temp, x_path, y_path in test_files:\n            X_test, y_test, _ = load_and_prepare_data(x_path, y_path, n_steps=best_config_dict['n_steps'])\n            yhat, metrics, errors = evaluate_model(model, X_test, y_test)\n            metrics['Temperature'] = temp\n            results.append(metrics)\n            all_predictions.append((temp, y_test, yhat, errors))\n            save_results(temp, y_test, yhat, errors, pd.DataFrame(results))\n\n        results_df = pd.DataFrame(results)\n        print(\"\\nPerformance Metrics Across Temperatures (Best Config):\")\n        print(results_df.set_index('Temperature'))\n\n        plot_training_evolution(\n            [(best_config_dict, best_history)],\n            [best_config_dict],\n            title_prefix=f\"Best_Config_Training_Evolution_n_steps_{best_config_dict['n_steps']}_\"\n                        f\"nodes_{best_config_dict['n_nodes']}_epochs_{best_config_dict['n_epochs']}_\"\n                        f\"batch_{best_config_dict['n_batch']}\"\n        )\n\n        plot_soc_and_error(all_predictions)\n        plot_error_metrics(results_df)\n    except Exception as e:\n        print(f\"Error in final evaluation: {e}\")\n    finally:\n        K.clear_session()\n        tf.keras.backend.clear_session()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T03:58:04.842309Z","iopub.execute_input":"2025-05-13T03:58:04.842855Z","iopub.status.idle":"2025-05-13T03:58:04.888882Z","shell.execute_reply.started":"2025-05-13T03:58:04.842827Z","shell.execute_reply":"2025-05-13T03:58:04.888164Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"%%time\nmain()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T03:58:12.252239Z","iopub.execute_input":"2025-05-13T03:58:12.252753Z","iopub.status.idle":"2025-05-13T03:58:12.259436Z","shell.execute_reply.started":"2025-05-13T03:58:12.252727Z","shell.execute_reply":"2025-05-13T03:58:12.258688Z"}},"outputs":[{"name":"stdout","text":"GPU memory growth enabled\nStarting grid search...\nGenerated 81 configurations: [{'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 32}, {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 150}, {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 256}, {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 50, 'n_batch': 32}, {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 50, 'n_batch': 150}]...\nEvaluating config 1/3: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 32}\nTesting at temperature -10°C with config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 32}\nError evaluating config {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 32}: repeat_evaluate() got multiple values for argument 'n_repeats'\nEvaluating config 2/3: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 150}\nTesting at temperature -10°C with config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 150}\nError evaluating config {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 150}: repeat_evaluate() got multiple values for argument 'n_repeats'\nEvaluating config 3/3: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 256}\nTesting at temperature -10°C with config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 256}\nError evaluating config {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 256}: repeat_evaluate() got multiple values for argument 'n_repeats'\nNo results collected. Check for errors in evaluation.\n\nGrid Search Results (sorted by RMSE):\nEmpty DataFrame\nColumns: []\nIndex: []\nGrid search failed to produce results.\nCPU times: user 2.4 ms, sys: 68 µs, total: 2.47 ms\nWall time: 2.34 ms\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"%%time\nmain()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-12T15:26:45.209311Z","iopub.execute_input":"2025-05-12T15:26:45.209566Z","iopub.status.idle":"2025-05-12T15:35:07.641949Z","shell.execute_reply.started":"2025-05-12T15:26:45.209547Z","shell.execute_reply":"2025-05-12T15:35:07.641171Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Starting grid search...\nEvaluating config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 128}\nRepeat 1/3 for config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 128}\nTRAINING MLP MODEL (nodes=55, epochs=5, batch_size=128)...\nEpoch 1/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0649 - val_loss: 0.0023\nEpoch 2/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0031 - val_loss: 0.0015\nEpoch 3/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0017 - val_loss: 0.0011\nEpoch 4/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 9.6785e-04\nEpoch 5/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 8.7959e-04\nPrediction in progress...\nRepeat 2/3 for config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 128}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"TRAINING MLP MODEL (nodes=55, epochs=5, batch_size=128)...\nEpoch 1/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0282 - val_loss: 0.0017\nEpoch 2/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0018 - val_loss: 0.0015\nEpoch 3/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0015 - val_loss: 0.0013\nEpoch 4/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0013\nEpoch 5/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0012\nPrediction in progress...\nRepeat 3/3 for config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 128}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"TRAINING MLP MODEL (nodes=55, epochs=5, batch_size=128)...\nEpoch 1/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0342 - val_loss: 0.0019\nEpoch 2/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0022 - val_loss: 0.0013\nEpoch 3/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 9.2436e-04\nEpoch 4/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 9.6319e-04\nEpoch 5/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 9.3003e-04 - val_loss: 8.3783e-04\nPrediction in progress...\nRepeat 1/3 for config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 128}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"TRAINING MLP MODEL (nodes=55, epochs=5, batch_size=128)...\nEpoch 1/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0414 - val_loss: 0.0028\nEpoch 2/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0020 - val_loss: 0.0011\nEpoch 3/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 0.0030\nEpoch 4/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 9.9249e-04 - val_loss: 8.0113e-04\nEpoch 5/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 9.1187e-04 - val_loss: 7.6584e-04\nPrediction in progress...\nRepeat 2/3 for config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 128}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"TRAINING MLP MODEL (nodes=55, epochs=5, batch_size=128)...\nEpoch 1/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0411 - val_loss: 0.0014\nEpoch 2/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0017 - val_loss: 0.0012\nEpoch 3/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0013 - val_loss: 9.9802e-04\nEpoch 4/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 9.4918e-04\nEpoch 5/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 9.7894e-04 - val_loss: 8.8645e-04\nPrediction in progress...\nRepeat 3/3 for config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 128}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"TRAINING MLP MODEL (nodes=55, epochs=5, batch_size=128)...\nEpoch 1/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.1023 - val_loss: 0.0065\nEpoch 2/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0047 - val_loss: 0.0021\nEpoch 3/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0023 - val_loss: 0.0012\nEpoch 4/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0014 - val_loss: 9.2077e-04\nEpoch 5/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 9.5115e-04 - val_loss: 0.0011\nPrediction in progress...\nRepeat 1/3 for config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 128}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"TRAINING MLP MODEL (nodes=55, epochs=5, batch_size=128)...\nEpoch 1/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2ms/step - loss: 0.0380 - val_loss: 0.0026\nEpoch 2/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0018 - val_loss: 0.0012\nEpoch 3/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 9.3190e-04\nEpoch 4/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 8.4946e-04\nEpoch 5/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 9.1405e-04 - val_loss: 9.1443e-04\nPrediction in progress...\nRepeat 2/3 for config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 128}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"TRAINING MLP MODEL (nodes=55, epochs=5, batch_size=128)...\nEpoch 1/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0623 - val_loss: 0.0077\nEpoch 2/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0019 - val_loss: 0.0024\nEpoch 3/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0014 - val_loss: 0.0016\nEpoch 4/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - loss: 0.0011 - val_loss: 9.1679e-04\nEpoch 5/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0010 - val_loss: 8.9052e-04\nPrediction in progress...\nRepeat 3/3 for config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 128}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"TRAINING MLP MODEL (nodes=55, epochs=5, batch_size=128)...\nEpoch 1/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0566 - val_loss: 0.0064\nEpoch 2/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0029 - val_loss: 0.0014\nEpoch 3/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0014 - val_loss: 0.0023\nEpoch 4/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0012 - val_loss: 0.0013\nEpoch 5/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 9.6088e-04 - val_loss: 8.0640e-04\nPrediction in progress...\nRepeat 1/3 for config: {'n_steps': 300, 'n_nodes': 55, 'n_epochs': 5, 'n_batch': 128}\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"TRAINING MLP MODEL (nodes=55, epochs=5, batch_size=128)...\nEpoch 1/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 2ms/step - loss: 0.0282 - val_loss: 0.0016\nEpoch 2/5\n\u001b[1m4186/4186\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - loss: 0.0019 - val_loss: 0.0013\nEpoch 3/5\n\u001b[1m1315/4186\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - loss: 0.0015","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/592933806.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting grid search...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0mconfigs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_configs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0mgrid_results_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_metric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RMSE'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nGrid Search Results (sorted by RMSE):\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/592933806.py\u001b[0m in \u001b[0;36mgrid_search\u001b[0;34m(configs, train_x_path, train_y_path, test_files, n_repeats, sort_metric)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;32mglobal\u001b[0m \u001b[0mX_test_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mX_test_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             metrics, histories = repeat_evaluate(\n\u001b[0m\u001b[1;32m    249\u001b[0m                 \u001b[0mtrain_x_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_repeats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_repeats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             )\n","\u001b[0;32m/tmp/ipykernel_31/592933806.py\u001b[0m in \u001b[0;36mrepeat_evaluate\u001b[0;34m(X_train, y_train, X_test, y_test, config, n_repeats)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mX_test_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_steps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         )\n\u001b[0;32m--> 224\u001b[0;31m         model, history = build_and_train_model(\n\u001b[0m\u001b[1;32m    225\u001b[0m             \u001b[0mX_train_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mn_nodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_nodes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_batch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_31/592933806.py\u001b[0m in \u001b[0;36mbuild_and_train_model\u001b[0;34m(X, y, n_input, n_nodes, epochs, batch_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"TRAINING MLP MODEL (nodes={n_nodes}, epochs={epochs}, batch_size={batch_size})...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     history = model.fit(\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":9},{"cell_type":"markdown","source":"## Took lots of time to complete a epoch \ndue to: \n- batch size being = 1\n- training loss did not go below 0.0025\n- validation loss did not go below 0.0021","metadata":{}},{"cell_type":"code","source":"!pip install scikeras","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:22:40.151038Z","iopub.execute_input":"2025-05-13T04:22:40.151780Z","iopub.status.idle":"2025-05-13T04:22:47.855418Z","shell.execute_reply.started":"2025-05-13T04:22:40.151755Z","shell.execute_reply":"2025-05-13T04:22:47.854554Z"}},"outputs":[{"name":"stdout","text":"Collecting scikeras\n  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\nRequirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.5.0)\nCollecting scikit-learn>=1.4.2 (from scikeras)\n  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.26.4)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\nRequirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.12.1)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.14.0)\nRequirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.4.1)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (24.2)\nRequirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.15.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.2)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->keras>=3.2.0->scikeras) (2.4.1)\nRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.13.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.1)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras>=3.2.0->scikeras) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->keras>=3.2.0->scikeras) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->keras>=3.2.0->scikeras) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->keras>=3.2.0->scikeras) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->keras>=3.2.0->scikeras) (2024.2.0)\nDownloading scikeras-0.13.0-py3-none-any.whl (26 kB)\nDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: scikit-learn, scikeras\n  Attempting uninstall: scikit-learn\n    Found existing installation: scikit-learn 1.2.2\n    Uninstalling scikit-learn-1.2.2:\n      Successfully uninstalled scikit-learn-1.2.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncategory-encoders 2.7.0 requires scikit-learn<1.6.0,>=1.0.0, but you have scikit-learn 1.6.1 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed scikeras-0.13.0 scikit-learn-1.6.1\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Sklearns GridSearchCV","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.mixed_precision import set_global_policy\nimport pandas as pd\nfrom sklearn.model_selection import GridSearchCV, KFold\nfrom sklearn.metrics import mean_squared_error\nimport os\nimport gc\nfrom itertools import product\n\n# Enable mixed precision for GPU optimization\nset_global_policy('mixed_float16')\nprint(\"Debug: Mixed precision enabled\")\n\n# Configure GPU memory growth\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n        print(\"Debug: GPU memory growth enabled\")\n    except Exception as e:\n        print(f\"Debug: Error configuring GPU: {e}\")\n\ndef load_and_prepare_data(file_x_path, file_y_path, n_steps=300, batch_size=256):\n    \"\"\"Load and preprocess data as a tf.data.Dataset.\"\"\"\n    try:\n        print(f\"Debug: Loading data from {file_x_path} and {file_y_path}\")\n        X = np.load(file_x_path, allow_pickle=True).T\n        y = np.load(file_y_path, allow_pickle=True).T\n        if np.any(np.isnan(X)) or np.any(np.isnan(y)):\n            raise ValueError(\"NaN values detected in input data\")\n        dataset = np.hstack((X, y))\n        print(f\"Debug: Dataset shape after hstack: {dataset.shape}\")\n        X, y = split_sequences(dataset, n_steps)\n        n_input = X.shape[1] * X.shape[2]\n        X = X.reshape((X.shape[0], n_input))\n        dataset = tf.data.Dataset.from_tensor_slices((X, y))\n        dataset = dataset.cache().batch(batch_size).prefetch(tf.data.AUTOTUNE)\n        print(f\"Debug: Loaded data: X.shape={X.shape}, y.shape={y.shape}, n_input={n_input}\")\n        return dataset, X, y, n_input\n    except Exception as e:\n        print(f\"Debug: Error in load_and_prepare_data: {e}\")\n        raise\n\ndef split_sequences(sequences, n_steps):\n    \"\"\"Split sequences into input-output pairs.\"\"\"\n    print(f\"Debug: Splitting sequences with n_steps={n_steps}\")\n    X, y = [], []\n    for i in range(len(sequences)):\n        end_ix = i + n_steps\n        if end_ix > len(sequences):\n            break\n        seq_x, seq_y = sequences[i:end_ix, :-1], sequences[end_ix-1, -1]\n        X.append(seq_x)\n        y.append(seq_y)\n    return np.array(X), np.array(y)\n\ndef build_model(n_nodes=55, n_input=1500):\n    \"\"\"Build MLP model.\"\"\"\n    try:\n        print(f\"Debug: Building model with n_nodes={n_nodes}, n_input={n_input}\")\n        model = Sequential([\n            Dense(n_nodes, activation='relu', input_dim=n_input),\n            Dense(n_nodes, activation='relu'),\n            Dense(n_nodes // 2, activation='relu'),\n            Dense(1, dtype='float32')\n        ])\n        model.compile(optimizer='adam', loss='mse')\n        return model\n    except Exception as e:\n        print(f\"Debug: Error in build_model: {e}\")\n        raise\n\ndef evaluate_model(model, dataset):\n    \"\"\"Evaluate model on a tf.data.Dataset.\"\"\"\n    try:\n        print(\"Debug: Evaluating model\")\n        X_test, y_test = [], []\n        for x, y in dataset.unbatch():\n            X_test.append(x.numpy())\n            y_test.append(y.numpy())\n        X_test, y_test = np.array(X_test), np.array(y_test)\n        print(f\"Debug: Test data shape: X_test={X_test.shape}, y_test={y_test.shape}\")\n        yhat = model.predict(X_test, verbose=1)\n        metrics, errors = evaluate_regression(y_test, yhat)\n        print(f\"Debug: Evaluation metrics: {metrics}\")\n        return yhat, metrics, errors\n    except Exception as e:\n        print(f\"Debug: Error in evaluate_model: {e}\")\n        raise\n\ndef evaluate_regression(y_true, y_pred):\n    \"\"\"Compute regression metrics and errors.\"\"\"\n    y_true = np.ravel(y_true)\n    y_pred = np.ravel(y_pred)\n    errors = y_true - y_pred\n    metrics = {\n        'MAE': mean_absolute_error(y_true, y_pred),\n        'MSE': mean_squared_error(y_true, y_pred),\n        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n        'R2': r2_score(y_true, y_pred),\n        'Max Error': max_error(y_true, y_pred),\n        'MAPE (%)': mean_absolute_percentage_error(y_true, y_pred) * 100\n    }\n    return metrics, errors\n\ndef save_results(temp, y_test, yhat, errors, results_df):\n    \"\"\"Save predictions, errors, and metrics.\"\"\"\n    try:\n        temp_clean = temp.replace('°C', 'C').replace('-', 'n')\n        print(f\"Debug: Saving results for {temp_clean}\")\n        np.save(f'/kaggle/working/MLP_npy_results/{temp_clean}_true_soc.npy', y_test)\n        np.save(f'/kaggle/working/MLP_npy_results/{temp_clean}_MLP_predicted_soc.npy', yhat)\n        np.save(f'/kaggle/working/MLP_npy_results/{temp_clean}_MLP_errors.npy', errors)\n        results_df.to_csv('/kaggle/working/MLP_prediction_metrics.csv', index=False)\n    except Exception as e:\n        print(f\"Debug: Error in save_results: {e}\")\n\ndef custom_grid_search(X_train, y_train, param_grid, cv=3):\n    \"\"\"Custom grid search for Keras model without KerasRegressor.\"\"\"\n    results = []\n    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n    param_combinations = list(product(\n        param_grid['n_steps'], param_grid['n_nodes'], param_grid['epochs'], param_grid['batch_size']\n    ))\n    print(f\"Debug: Starting custom grid search with {len(param_combinations)} combinations\")\n\n    for idx, (n_steps, n_nodes, epochs, batch_size) in enumerate(param_combinations[:3]):  # Debug with first 3\n        print(f\"Debug: Evaluating config {idx+1}/{len(param_combinations[:3])}: n_steps={n_steps}, n_nodes={n_nodes}, epochs={epochs}, batch_size={batch_size}\")\n        cv_scores = []\n        \n        # Reload data for n_steps\n        train_dataset, X_train, y_train, n_input = load_and_prepare_data(\n            train_x_path, train_y_path, n_steps=n_steps, batch_size=batch_size\n        )\n        \n        for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n            print(f\"Debug: Training fold {fold+1}/{cv}\")\n            X_tr, X_val = X_train[train_idx], X_train[val_idx]\n            y_tr, y_val = y_train[train_idx], y_train[val_idx]\n            \n            # Build and train model\n            model = build_model(n_nodes=n_nodes, n_input=n_input)\n            train_dataset = tf.data.Dataset.from_tensor_slices((X_tr, y_tr)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n            val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n            \n            try:\n                model.fit(\n                    train_dataset,\n                    validation_data=val_dataset,\n                    epochs=epochs,\n                    verbose=1\n                )\n                # Evaluate on validation fold\n                y_pred = model.predict(X_val, verbose=0)\n                mse = mean_squared_error(y_val, y_pred)\n                cv_scores.append(mse)\n                print(f\"Debug: Fold {fold+1} MSE: {mse}\")\n            except Exception as e:\n                print(f\"Debug: Error in fold {fold+1}: {e}\")\n                cv_scores.append(np.inf)\n            finally:\n                tf.keras.backend.clear_session()\n                del model\n                gc.collect()\n        \n        # Store results\n        mean_mse = np.mean(cv_scores)\n        results.append({\n            'n_steps': n_steps,\n            'n_nodes': n_nodes,\n            'epochs': epochs,\n            'batch_size': batch_size,\n            'mean_mse': mean_mse,\n            'rmse': np.sqrt(mean_mse)\n        })\n        print(f\"Debug: Config RMSE: {np.sqrt(mean_mse)}\")\n    \n    results_df = pd.DataFrame(results)\n    sorted_df = results_df.sort_values(by='rmse')\n    print(\"Debug: Grid search results:\")\n    print(sorted_df)\n    sorted_df.to_csv('/kaggle/working/MLP_grid_search_results.csv', index=False)\n    return sorted_df\n\ndef main():\n    global train_x_path, train_y_path  # For load_and_prepare_data\n    # Create output directories\n    os.makedirs('/kaggle/working/MLP_npy_results', exist_ok=True)\n    os.makedirs('/kaggle/working/MLP_plots', exist_ok=True)\n    print(\"Debug: Output directories created\")\n\n    # Define file paths\n    train_x_path = '/kaggle/input/lg-hg2-npy-data/train/TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs_X.npy'\n    train_y_path = '/kaggle/input/lg-hg2-npy-data/train/TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs_Y.npy'\n    test_files = [\n        ('-10°C', '/kaggle/input/lg-hg2-npy-data/test/01_TEST_LGHG2@n10degC_Norm_(05_Inputs)_X.npy',\n                  '/kaggle/input/lg-hg2-npy-data/test/01_TEST_LGHG2@n10degC_Norm_(05_Inputs)_Y.npy'),\n        ('0°C', '/kaggle/input/lg-hg2-npy-data/test/02_TEST_LGHG2@0degC_Norm_(05_Inputs)_X.npy',\n                '/kaggle/input/lg-hg2-npy-data/test/02_TEST_LGHG2@0degC_Norm_(05_Inputs)_Y.npy'),\n        ('10°C', '/kaggle/input/lg-hg2-npy-data/test/03_TEST_LGHG2@10degC_Norm_(05_Inputs)_X.npy',\n                 '/kaggle/input/lg-hg2-npy-data/test/03_TEST_LGHG2@10degC_Norm_(05_Inputs)_Y.npy'),\n        ('25°C', '/kaggle/input/lg-hg2-npy-data/test/04_TEST_LGHG2@25degC_Norm_(05_Inputs)_X.npy',\n                 '/kaggle/input/lg-hg2-npy-data/test/04_TEST_LGHG2@25degC_Norm_(05_Inputs)_Y.npy')\n    ]\n\n    # Load training data for grid search\n    print(\"Debug: Loading training data\")\n    train_dataset, X_train, y_train, n_input = load_and_prepare_data(train_x_path, train_y_path, n_steps=300, batch_size=256)\n\n    # Define parameter grid\n    param_grid = {\n        'n_steps': [300, 500, 700],\n        'n_nodes': [55, 128, 256],\n        'epochs': [5, 50, 120],\n        'batch_size': [32, 150, 256]\n    }\n    print(f\"Debug: Parameter grid defined with {len(param_grid['n_steps']) * len(param_grid['n_nodes']) * len(param_grid['epochs']) * len(param_grid['batch_size'])} combinations\")\n\n    # Perform grid search\n    print(\"Debug: Starting grid search\")\n    grid_results_df = custom_grid_search(X_train, y_train, param_grid, cv=3)\n\n    if grid_results_df.empty:\n        print(\"Debug: Grid search failed to produce results\")\n        return\n\n    # Get best configuration\n    best_config = grid_results_df.iloc[0]\n    best_config_dict = {\n        'n_steps': int(best_config['n_steps']),\n        'n_nodes': int(best_config['n_nodes']),\n        'epochs': int(best_config['epochs']),\n        'batch_size': int(best_config['batch_size'])\n    }\n    print(f\"\\nDebug: Best configuration: {best_config_dict}\")\n\n    # Train model with best configuration\n    print(\"Debug: Training model with best configuration\")\n    train_dataset, _, _, n_input = load_and_prepare_data(\n        train_x_path, train_y_path, n_steps=best_config_dict['n_steps'], batch_size=best_config_dict['batch_size']\n    )\n    best_model = build_model(n_nodes=best_config_dict['n_nodes'], n_input=n_input)\n    history = best_model.fit(\n        train_dataset,\n        epochs=best_config_dict['epochs'],\n        verbose=1\n    )\n\n    # Evaluate on all test temperatures\n    print(\"\\nDebug: Evaluating best model on test temperatures\")\n    results = []\n    all_predictions = []\n    for temp, x_path, y_path in test_files:\n        print(f\"Debug: Evaluating at {temp}\")\n        test_dataset, _, y_test, _ = load_and_prepare_data(\n            x_path, y_path, n_steps=best_config_dict['n_steps'], batch_size=best_config_dict['batch_size']\n        )\n        yhat, metrics, errors = evaluate_model(best_model, test_dataset)\n        metrics['Temperature'] = temp\n        results.append(metrics)\n        all_predictions.append((temp, y_test, yhat, errors))\n        save_results(temp, y_test, yhat, errors, pd.DataFrame(results))\n\n    results_df = pd.DataFrame(results)\n    print(\"\\nDebug: Performance Metrics Across Temperatures (Best Config):\")\n    print(results_df.set_index('Temperature'))\n    results_df.to_csv('/kaggle/working/MLP_test_results.csv', index=False)\n\n    # Plot results (assuming plotting functions are defined)\n    try:\n        print(\"Debug: Generating plots\")\n        plot_training_evolution(\n            [(best_config_dict, history.history)],\n            [best_config_dict],\n            title_prefix=f\"Best_Config_Training_Evolution_n_steps_{best_config_dict['n_steps']}_\"\n                        f\"nodes_{best_config_dict['n_nodes']}_epochs_{best_config_dict['n_epochs']}_\"\n                        f\"batch_{best_config_dict['n_batch']}\"\n        )\n        plot_soc_and_error(all_predictions)\n        plot_error_metrics(results_df)\n    except Exception as e:\n        print(f\"Debug: Error in plotting: {e}\")\n\n    # Clean up\n    tf.keras.backend.clear_session()\n    gc.collect()\n    print(\"Debug: Session cleared\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:27:55.007506Z","iopub.execute_input":"2025-05-13T04:27:55.007807Z","iopub.status.idle":"2025-05-13T04:27:56.613968Z","shell.execute_reply.started":"2025-05-13T04:27:55.007785Z","shell.execute_reply":"2025-05-13T04:27:56.613206Z"}},"outputs":[{"name":"stdout","text":"Debug: Mixed precision enabled\nDebug: GPU memory growth enabled\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"%%time\nimport time\nmain()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:28:00.603251Z","iopub.execute_input":"2025-05-13T04:28:00.603517Z","execution_failed":"2025-05-13T04:36:00.777Z"}},"outputs":[{"name":"stdout","text":"Debug: Output directories created\nDebug: Loading training data\nDebug: Loading data from /kaggle/input/lg-hg2-npy-data/train/TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs_X.npy and /kaggle/input/lg-hg2-npy-data/train/TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs_Y.npy\nDebug: Dataset shape after hstack: (669956, 6)\nDebug: Splitting sequences with n_steps=300\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1747110485.157218      31 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Debug: Loaded data: X.shape=(669657, 1500), y.shape=(669657,), n_input=1500\nDebug: Parameter grid defined with 81 combinations\nDebug: Starting grid search\nDebug: Starting custom grid search with 81 combinations\nDebug: Evaluating config 1/3: n_steps=300, n_nodes=55, epochs=5, batch_size=32\nDebug: Loading data from /kaggle/input/lg-hg2-npy-data/train/TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs_X.npy and /kaggle/input/lg-hg2-npy-data/train/TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs_Y.npy\nDebug: Dataset shape after hstack: (669956, 6)\nDebug: Splitting sequences with n_steps=300\nDebug: Loaded data: X.shape=(669657, 1500), y.shape=(669657,), n_input=1500\nDebug: Training fold 1/3\nDebug: Building model with n_nodes=55, n_input=1500\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1747110523.453722     100 service.cc:148] XLA service 0x7bf270009c90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1747110523.457644     100 service.cc:156]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1747110523.809638     100 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  121/13952\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 1ms/step - loss: 0.0096","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1747110524.872864     100 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m13952/13952\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 2ms/step - loss: 0.0040 - val_loss: 0.1150\nEpoch 2/5\n\u001b[1m13952/13952\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 2ms/step - loss: 0.0970 - val_loss: 0.1151\nEpoch 3/5\n\u001b[1m13952/13952\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.1129 - val_loss: 0.1146\nEpoch 4/5\n\u001b[1m13952/13952\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.1151 - val_loss: 0.1146\nEpoch 5/5\n\u001b[1m13952/13952\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.1151 - val_loss: 0.1146\nDebug: Fold 1 MSE: 0.11461792141199112\nDebug: Training fold 2/3\nDebug: Building model with n_nodes=55, n_input=1500\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m13952/13952\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 2ms/step - loss: 0.0020 - val_loss: 1.9631\nEpoch 2/5\n\u001b[1m13952/13952\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.0275 - val_loss: 0.1135\nEpoch 3/5\n\u001b[1m13952/13952\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.1107 - val_loss: 0.1142\nEpoch 4/5\n\u001b[1m13952/13952\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 2ms/step - loss: 0.1145 - val_loss: 0.1145\nEpoch 5/5\n\u001b[1m13952/13952\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 2ms/step - loss: 0.1149 - val_loss: 0.1145\nDebug: Fold 2 MSE: 0.11448808759450912\nDebug: Training fold 3/3\nDebug: Building model with n_nodes=55, n_input=1500\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m 6048/13952\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 0.0020","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# Paths for training and test data\ntrain_x_path = '/kaggle/input/lg-hg2-npy-data/train/TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs_X.npy'\ntrain_y_path = '/kaggle/input/lg-hg2-npy-data/train/TRAIN_LGHG2@n10degC_to_25degC_Norm_5Inputs_Y.npy'\n\ntest_files = [\n    ('-10°C', '/kaggle/input/lg-hg2-npy-data/test/01_TEST_LGHG2@n10degC_Norm_(05_Inputs)_X.npy',\n              '/kaggle/input/lg-hg2-npy-data/test/01_TEST_LGHG2@n10degC_Norm_(05_Inputs)_Y.npy'),\n    ('0°C', '/kaggle/input/lg-hg2-npy-data/test/02_TEST_LGHG2@0degC_Norm_(05_Inputs)_X.npy',\n            '/kaggle/input/lg-hg2-npy-data/test/02_TEST_LGHG2@0degC_Norm_(05_Inputs)_Y.npy'),\n    ('10°C', '/kaggle/input/lg-hg2-npy-data/test/03_TEST_LGHG2@10degC_Norm_(05_Inputs)_X.npy',\n             '/kaggle/input/lg-hg2-npy-data/test/03_TEST_LGHG2@10degC_Norm_(05_Inputs)_Y.npy'),\n    ('25°C', '/kaggle/input/lg-hg2-npy-data/test/04_TEST_LGHG2@25degC_Norm_(05_Inputs)_X.npy',\n             '/kaggle/input/lg-hg2-npy-data/test/04_TEST_LGHG2@25degC_Norm_(05_Inputs)_Y.npy')\n]\n\n# Root mean squared error\ndef measure_rmse(actual, predicted):\n    return sqrt(mean_squared_error(actual, predicted))\n\n# Fit a model\ndef model_fit(train_x, train_y, config):\n    # Unpack config\n    n_nodes, n_epochs, n_batch = config\n    # Define model\n    model = Sequential()\n    model.add(Dense(n_nodes, activation='relu', input_dim=5))  # 5 features\n    model.add(Dense(1))  # Single output for SOC\n    model.compile(loss='mse', optimizer='adam')\n    model.summary()\n    # Fit model\n    model.fit(train_x, train_y, epochs=n_epochs, batch_size=n_batch, verbose=1)\n    return model\n\n# Predict with the fit model\ndef model_predict(model, test_x):\n    # Make predictions\n    yhat = model.predict(test_x, verbose=0)\n    return yhat.flatten()  # Flatten to match actual labels shape\n\n# Evaluate model on a test set\ndef evaluate_model(train_x, train_y, test_x, test_y, config):\n    # Fit model\n    model = model_fit(train_x, train_y, config)\n    # Predict\n    predictions = model_predict(model, test_x)\n    # Calculate RMSE\n    error = measure_rmse(test_y.flatten(), predictions)\n    print(f' > RMSE: {error:.3f}')\n    return error\n\n# Repeat evaluation for a configuration\ndef repeat_evaluate(train_x, train_y, test_x, test_y, config, n_repeats=1):\n    train_x = train_x.T\n    train_y = train_y.T\n    test_x = test_x.T\n    test_y = test_y.T\n    \n    key = str(config)\n    # Evaluate model multiple times\n    scores = [evaluate_model(train_x, train_y, test_x, test_y, config) for _ in range(n_repeats)]\n    # Summarize score\n    result = np.mean(scores)\n    print(f'> Model[{key}] Mean RMSE: {result:.3f}')\n    return key, result\n\n# Grid search configurations\ndef grid_search(train_x, train_y, test_files, cfg_list):\n    scores_by_temp = {temp: [] for temp, _, _ in test_files}\n    # Evaluate each configuration\n    for cfg in cfg_list:\n        print(f'Evaluating config: {cfg}')\n        for temp, test_x_path, test_y_path in test_files:\n            # Load test data\n            test_x = np.load(test_x_path)\n            test_y = np.load(test_y_path)\n            # Evaluate config\n            key, score = repeat_evaluate(train_x, train_y, test_x, test_y, cfg)\n            scores_by_temp[temp].append((key, score))\n    # Sort scores by error for each temperature\n    for temp in scores_by_temp:\n        scores_by_temp[temp].sort(key=lambda tup: tup[1])\n    return scores_by_temp\n\n# Create a list of configurations to try\ndef model_configs():\n    n_nodes = [55, 100]\n    n_epochs = [5, 50]\n    n_batch = [32, 150]\n    configs = [[i, j, k] for i in n_nodes for j in n_epochs for k in n_batch]\n    print(f'Total configs: {len(configs)}')\n    return configs\n\n# Main execution\ndef main():\n    # Load training data\n    train_x = np.load(train_x_path)\n    train_y = np.load(train_y_path)\n    \n    # Ensure shapes are correct\n    print(f'Train X shape: {train_x.shape}, Train Y shape: {train_y.shape}')\n    \n    # Model configs\n    cfg_list = model_configs()\n    \n    # Grid search\n    scores = grid_search(train_x, train_y, test_files, cfg_list)\n    \n    # Print results\n    print('Done')\n    for temp in scores:\n        print(f'\\nTop 3 configs for {temp}:')\n        for cfg, error in scores[temp][:3]:\n            print(f'Config: {cfg}, RMSE: {error:.3f}')\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T04:51:45.372817Z","iopub.execute_input":"2025-05-13T04:51:45.373126Z","execution_failed":"2025-05-13T06:15:06.344Z"}},"outputs":[{"name":"stdout","text":"Train X shape: (5, 669956), Train Y shape: (1, 669956)\nTotal configs: 8\nEvaluating config: [55, 5, 32]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_5\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0059\nEpoch 2/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 6.2338e-04\nEpoch 3/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.8719e-04\nEpoch 4/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 5.6877e-04\nEpoch 5/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.5375e-04\n > RMSE: 0.021\n> Model[[55, 5, 32]] Mean RMSE: 0.021\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_6\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0029\nEpoch 2/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 6.9350e-04\nEpoch 3/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 6.2953e-04\nEpoch 4/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 6.0606e-04\nEpoch 5/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.9346e-04\n > RMSE: 0.018\n> Model[[55, 5, 32]] Mean RMSE: 0.018\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_7\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0029\nEpoch 2/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 6.5241e-04\nEpoch 3/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 6.0516e-04\nEpoch 4/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.9460e-04\nEpoch 5/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.8261e-04\n > RMSE: 0.018\n> Model[[55, 5, 32]] Mean RMSE: 0.018\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_8\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0043\nEpoch 2/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 6.7318e-04\nEpoch 3/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 6.4175e-04\nEpoch 4/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 6.0953e-04\nEpoch 5/5\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.6915e-04\n > RMSE: 0.014\n> Model[[55, 5, 32]] Mean RMSE: 0.014\nEvaluating config: [55, 5, 150]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_9\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 0.0314\nEpoch 2/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 7.8424e-04\nEpoch 3/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 6.8829e-04\nEpoch 4/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 6.4265e-04\nEpoch 5/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 6.1358e-04\n > RMSE: 0.018\n> Model[[55, 5, 150]] Mean RMSE: 0.018\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_10\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 0.0190\nEpoch 2/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 7.6935e-04\nEpoch 3/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 6.9347e-04\nEpoch 4/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 6.5818e-04\nEpoch 5/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 6.3768e-04\n > RMSE: 0.021\n> Model[[55, 5, 150]] Mean RMSE: 0.021\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_11\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 0.0333\nEpoch 2/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 8.6314e-04\nEpoch 3/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 7.3481e-04\nEpoch 4/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 6.6276e-04\nEpoch 5/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 6.1547e-04\n > RMSE: 0.018\n> Model[[55, 5, 150]] Mean RMSE: 0.018\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_12\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_12\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - loss: 0.0099\nEpoch 2/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 7.3328e-04\nEpoch 3/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 6.3287e-04\nEpoch 4/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 5.9031e-04\nEpoch 5/5\n\u001b[1m4467/4467\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1ms/step - loss: 5.7649e-04\n > RMSE: 0.014\n> Model[[55, 5, 150]] Mean RMSE: 0.014\nEvaluating config: [55, 50, 32]\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_13\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_13\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_27 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step - loss: 0.0040\nEpoch 2/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 6.3132e-04\nEpoch 3/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.9091e-04\nEpoch 4/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.7863e-04\nEpoch 5/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.6609e-04\nEpoch 6/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.6415e-04\nEpoch 7/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.5985e-04\nEpoch 8/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.5232e-04\nEpoch 9/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.5452e-04\nEpoch 10/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.5038e-04\nEpoch 11/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.4600e-04\nEpoch 12/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.3650e-04\nEpoch 13/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.4198e-04\nEpoch 14/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.3716e-04\nEpoch 15/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.3147e-04\nEpoch 16/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.2608e-04\nEpoch 17/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.2883e-04\nEpoch 18/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.2764e-04\nEpoch 19/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.2149e-04\nEpoch 20/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.2230e-04\nEpoch 21/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.1989e-04\nEpoch 22/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.1577e-04\nEpoch 23/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.1840e-04\nEpoch 24/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.0634e-04\nEpoch 25/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.1238e-04\nEpoch 26/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.0380e-04\nEpoch 27/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.1214e-04\nEpoch 28/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.0249e-04\nEpoch 29/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.0936e-04\nEpoch 30/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 4.9975e-04\nEpoch 31/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.0359e-04\nEpoch 32/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.0713e-04\nEpoch 33/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.0581e-04\nEpoch 34/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.0119e-04\nEpoch 35/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.0399e-04\nEpoch 36/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.0005e-04\nEpoch 37/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.0029e-04\nEpoch 38/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.1228e-04\nEpoch 39/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.0364e-04\nEpoch 40/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.0514e-04\nEpoch 41/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.0129e-04\nEpoch 42/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.0272e-04\nEpoch 43/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.0023e-04\nEpoch 44/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 4.9967e-04\nEpoch 45/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 4.9501e-04\nEpoch 46/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 5.0752e-04\nEpoch 47/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 4.9511e-04\nEpoch 48/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 4.9593e-04\nEpoch 49/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 4.9901e-04\nEpoch 50/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 4.9512e-04\n > RMSE: 0.020\n> Model[[55, 50, 32]] Mean RMSE: 0.020\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential_14\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_14\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_28 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m55\u001b[0m)                  │             \u001b[38;5;34m330\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_29 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m56\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ dense_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">330</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m386\u001b[0m (1.51 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">386</span> (1.51 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"name":"stdout","text":"Epoch 1/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1ms/step - loss: 0.0066\nEpoch 2/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 1ms/step - loss: 6.3993e-04\nEpoch 3/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 6.1232e-04\nEpoch 4/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.9543e-04\nEpoch 5/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.8994e-04\nEpoch 6/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.7582e-04\nEpoch 7/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.8112e-04\nEpoch 8/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.6761e-04\nEpoch 9/50\n\u001b[1m20937/20937\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 1ms/step - loss: 5.6705e-04\nEpoch 10/50\n\u001b[1m12212/20937\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - loss: 5.6143e-04","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}